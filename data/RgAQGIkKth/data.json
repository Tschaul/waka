{"dateCreated":"2011-08-15 10:01:42","dateTouched":"2011-08-15 10:01:42","dateUsersTouched":"2011-08-21 11:22:18","maxPostId":13,"maxFileId":2,"maxImageId":1,"starter":{"title":"Fiber-Reconstruction","content":"Paper ([url]http:\/\/dl.dropbox.com\/u\/1720979\/projects\/fibrometry\/reconstruction.pdf[\/url])\nzur Fibrometry: ([url]http:\/\/dasunwahrscheinliche.de\/waka\/?w=mwCNA7BtP8&u=7xSnADQ3k3[\/url])","files":[],"images":[],"dateContentTouched":"2011-08-15 12:10:58","dateImagesTouched":"2011-08-15 10:01:42","dateFilesTouched":"2011-08-15 10:01:42"},"posts":[{"id":2,"content":"","title":"Tables","dateCreated":"2011-08-15 10:11:11","dateContentTouched":"2011-08-24 07:08:51","dateImagesTouched":"2011-08-15 10:11:11","dateFilesTouched":"2011-08-15 10:11:11","dateCommentsTouched":"2011-08-15 10:11:11","files":[],"images":[],"comments":[],"users":{"claus.metzner@gmx.net":{"mayEdit":1,"dateRead":"2011-08-24 12:20:14","dateTouched":"2011-08-24 07:08:51"},"janina.lange@web.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-20 17:43:51"},"Patrick.Krauss@web.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-24 07:09:38"},"nadine.r.lang@gmx.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"1985-09-02 14:00:00"}},"dateUsersTouched":"2011-08-24 07:08:49"},{"id":3,"content":"","title":"Figure Legends","dateCreated":"2011-08-15 10:11:34","dateContentTouched":"2011-08-24 07:08:37","dateImagesTouched":"2011-08-15 10:11:34","dateFilesTouched":"2011-08-15 10:11:34","dateCommentsTouched":"2011-08-15 10:11:34","files":[],"images":[],"comments":[],"users":{"claus.metzner@gmx.net":{"mayEdit":1,"dateRead":"2011-08-24 12:20:13","dateTouched":"2011-08-24 07:08:37"},"janina.lange@web.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-20 17:43:47"},"Patrick.Krauss@web.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-24 07:09:36"},"nadine.r.lang@gmx.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"1985-09-02 14:00:00"}},"dateUsersTouched":"2011-08-24 07:08:36"},{"id":4,"content":"Quantification of Three-Dimensional Cell-Mediated Collagen Remodeling Using Graph Theory\n","title":"References","dateCreated":"2011-08-15 10:11:50","dateContentTouched":"2011-08-24 07:08:23","dateImagesTouched":"2011-08-15 10:11:50","dateFilesTouched":"2011-08-17 06:39:05","dateCommentsTouched":"2011-08-24 05:04:24","files":[{"url":"data\/RgAQGIkKth\/files\/2\/Quantification of Three-Dimensional Cell-Mediated Collagen Remodeling Using Graph Theory.pdf","dateCreated":"2011-08-17 06:39:05","id":2,"name":"Quantification of Three-Dimensional Cell-Mediated Collagen Remodeling Using Graph Theory.pdf"}],"images":[],"comments":[{"id":2,"user":"Patrick.Krauss@web.de","content":"Ich habe alle Eintr\u00e4ge meiner BA in das references.bib File des R-Papers \u00fcbertragen.","dateCreated":"2011-08-24 05:04:24"}],"users":{"claus.metzner@gmx.net":{"mayEdit":1,"dateRead":"2011-08-26 06:47:52","dateTouched":"2011-08-24 07:08:23"},"janina.lange@web.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-20 17:43:41"},"Patrick.Krauss@web.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-29 08:39:13"},"nadine.r.lang@gmx.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-28 09:52:02"}},"dateUsersTouched":"2011-08-24 07:08:19","maxCommentId":2},{"id":5,"content":"Liste der Bilder f\u00fcr Results-Section\nR:P(r_nod)\nR:Bilder 2D vorher nachher (blau\/rot\/gr\u00fcn = Ebenen):\nR:Abh. Laserleistung + Gain (2x)\n\n\n----------------------------------------------------------------------------------------\n\nSummary and Outlook:\n\n- Subpixel -> Claus\n- Fiber parametr. -> Patrick","title":"Results and Discussion","dateCreated":"2011-08-15 10:12:08","dateContentTouched":"2011-08-30 10:45:23","dateImagesTouched":"2011-08-15 10:12:08","dateFilesTouched":"2011-08-15 10:12:08","dateCommentsTouched":"2011-08-30 05:11:34","files":[],"images":[],"comments":[{"id":2,"user":"janina.lange@web.de","content":"Kannst dir bis heute Nachmittag gerne \u00fcberlegen, was ich noch zum Fiber-Recognition-Paper beitragen k\u00f6nnte!","dateCreated":"2011-08-29 08:52:13"},{"id":3,"user":"Patrick.Krauss@web.de","content":"Vielen Dank ! \nK\u00f6nntest du evtl ein paar Plots machen, wenn ich dir die entsprechenden Rohdaten gebe?\nDann br\u00e4uchte ich mich nicht l\u00e4nger mit MatLab aufhalten und kann die Methods- und Results-Section gar fertig schreiben bis wir uns treffen.","dateCreated":"2011-08-29 09:04:56"},{"id":4,"user":"janina.lange@web.de","content":"Also jetzt und heute kann ich gar keine Plots machen, weil ich in der Arbeit bin. W\u00fcrde morgen reichen?","dateCreated":"2011-08-29 10:17:03"},{"id":5,"user":"Patrick.Krauss@web.de","content":"Ja klar.","dateCreated":"2011-08-29 10:30:38"}],"users":{"claus.metzner@gmx.net":{"mayEdit":1,"dateRead":"2011-08-30 14:06:37","dateTouched":"2011-08-24 13:13:25"},"janina.lange@web.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-30 08:20:42"},"Patrick.Krauss@web.de":{"mayEdit":1,"dateTouched":"2011-08-30 10:45:23","dateRead":"2011-08-30 14:05:56"},"nadine.r.lang@gmx.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-28 09:52:15"}},"dateUsersTouched":"2011-08-24 13:13:24","maxCommentId":7},{"id":6,"content":"\n\\\\paragraph{Distribution of grayscales in typical stacks}\n\n\n\n\n\\\\paragraph{Generation of Surrogate Data Sets}\n\nTo convert the binary data set into a grayscale data set we apply a process called numeric blurring which simulates the imaging process. Numeric blurring is done in four subsequent steps:\n\\\\begin{enumerate}\n\n  \\\\item The binary 3D-array of voxels is converted into a grayscale 3D-array by setting all voxels with value 1 to brightness values $B \\\\in [0,255]$ according to the polar angle $\\\\vartheta$ of the line to which they belong. This procedure replicates the blind spot effect (i.e. a gradual darkening of steep fibers) as described in \\\\cite{jaw09}.\n\n\t\\\\item A sample of dark voxels is randomly chosen and set to brightness values $>200$. This simulates dirt particles within the fluid phase that appear as isolated bright fluctuations in the original microscope images\n\t\t\n\t\\\\item The 3D-array of voxels is convoluted with an anisotropic Gaussian to simulate the point spread function. \n\t\\\\begin{align}\n    B(x,y,z) &:= (B \\\\ast psf)(x,y,z) \\\\\\\\\n    B(x,y,z) &:= \\\\iiint\\\\limits_{}B(x\\',y\\',z\\')psf(x-x\\',y-y\\',z-z\\')dx\\' \\\\, dy\\' \\\\, dz\\'\n  \\\\end{align}\n  where $B(x,y,z) \\\\in \\\\left[0,255\\\\right]$ is brightness of voxel $(x,y,z)$. The point spread function is defined as \\\\\\\\\n  $psf(x-x\\',y-y\\',z-z\\') = \\\\exp\\\\left(-\\\\left(\\\\frac{(x-x\\')^{2}}{\\\\sigma_{x}^{2}}+\\\\frac{(y-y\\')^{2}}{\\\\sigma_{y}^{2}}+\\\\frac{(z-z\\')^{2}}{\\\\sigma_{z}^{2}}\\\\right)\\\\right)$ with $\\\\sigma_x=\\\\sigma_y<\\\\sigma_z$ according to characteristics of confocal microscopy.\n\t\t\n\t\\\\item A Gaussian distributed random variable with mean $\\\\mu=15$ and variance $\\\\sigma^2=4$ is added to each voxel to simulate noise.\n\t\n\\\\end{enumerate}\n\n\n\n\\\\paragraph{Preprocessing}\n\nSome data sets show z-dependence of mean gray scale. The average brightness of each z-slice $\\\\mu(z)$ is not constant in all layers, but rather decreases for deeper located slices in stack. This effect is due to scattering and absorption of light by collagene fibers and ambient medium. \n\nFor compensation the data set is firstly normalized to an equal global mean gray scale, disregarding statistical fluctuations:\n\\\\begin{align}\n\tG_{xyz} &:= G_{xyz}-\\\\mu(z) &  \\\\forall \\\\ x,y,z \\\\\\\\\n\t\\\\intertext{and secondly rescaled to values $\\\\left[0,1\\\\right]$ by affine transformation:}\n\tG_{xyz} &:= \\\\frac{G_{xyz} - \\\\min\\\\left\\\\{G_{ijk}\\\\right\\\\}} {\\\\max\\\\left\\\\{G_{ijk}\\\\right\\\\} - \\\\min\\\\left\\\\{G_{ijk}\\\\right\\\\}} & \\\\forall \\\\ x,y,z,i,j,k \n\\\\end{align}\t\nwhere $ \\\\mu(z)=\\\\frac{1}{N_x N_Y}\\\\sum\\\\limits_{i=1}^{N_x}\\\\sum\\\\limits_{j=1}^{N_y} G_{ijz} $\n\\\\begin{figure}[htb]\n\t\\\\centering\n\t\\\\includegraphics[width=0.8\\\\textwidth]{images\/prepro.jpg}\n\t\\\\caption{mean gray scales: before and after pre-processing}\n\t\\\\label{fig:preprocessing}\n\\\\end{figure}\n\n\n\\\\paragraph{Template Computation}\n\nThe templates are derived automatically from the gray scale data set. The process requires neither any knowledge of point spread function\\'s characteristics nor any user interactions. Since fiber detection is performed in three directions (x, y and z) and the point spread function may be anisotropic, three different templates $\\\\mathbf T_x, \\\\mathbf T_y, \\\\mathbf T_z$ are required. One for each direction. \n\\\\begin{enumerate}\n\n\t\\\\item A sufficient large sample of voxels is picked out randomly. We chose a number of $10^5$. Only voxels with intensities greater than the global mean intensity $\\\\mu$ were accepted. This restriction is only due to limit computation time.\n\t\n\t\\\\item Each voxel is center of three small two-dimensional (2D) images ($I_x, I_y, I_z$), where the first image is located in the yz-plane, the second in the xz- and the third in the xy-plane. Images\\' height $H$ and width $W$ are initially set to arbitrary small values. The adaptive resizing process is described in later section.\n \n\t\\\\item These small images are represented as matrices $\\\\mathbf P_1,\\\\mathbf P_2,\\\\ldots,\\\\mathbf P_N$ with matrix entries corresponding to voxel brightnesses and with size $H\\\\times W$. They are used as training patterns. Hence three sets of training patterns $\\\\left\\\\{\\\\mathbf P^x_i\\\\right\\\\}, \\\\left\\\\{\\\\mathbf P^y_i\\\\right\\\\}, \\\\left\\\\{\\\\mathbf P^z_i\\\\right\\\\}$ are obtained to compute the three different templates. \n\t\t\n\t\\\\item From all training patterns of each set the weighted average pattern $\\\\mathbf A$ is computed:\n\t\t\\\\begin{equation}\n\t\t\t\\\\mathbf{A}:=\\\\frac{\\\\sum\\\\limits_i w_i\\\\mathbf P_i}{\\\\sum\\\\limits_i w_{i}}\n\t\t\\\\end{equation}\n\t\twhere $w_i$ is the central entry of matrix $\\\\mathbf P_i$ liegt. \\\\\\\\\n\t\tThe idea behind this weightening is that the greater a voxel\\'s intensity is the more probably this voxel represents a collagen fiber.\n\t\n\t\\\\item To become independent from absolute brightnesses the global mean gray scale $\\\\mu$ is subtracted from each matrix entry:\n\t\\\\begin{equation}\n\t  (a_{ij})_{H \\\\times W}:=(a_{ij})_{H \\\\times W}-\\\\mu\n\t\\\\end{equation}\n\t\\\\begin{equation}\n\t\t\\\\mathbf{A}:=\\\\mathbf{A}-\\\\mu=\n\t\t\\\\begin{pmatrix}\n\t\t\ta_{1,1}-\\\\mu & a_{1,2}-\\\\mu & \\\\cdots &  a_{1,W}-\\\\mu \\\\\\\\\n\t\t\ta_{2,1}-\\\\mu & a_{2,2}-\\\\mu & \\\\cdots & a_{2,W}-\\\\mu \\\\\\\\\n\t\t\t\\\\vdots & \\\\vdots & \\\\ddots & \\\\vdots \\\\\\\\\n\t\t\ta_{H,1}-\\\\mu & a_{H,2}-\\\\mu & \\\\cdots & a_{H,W}-\\\\mu\n\t\t\\\\end{pmatrix} \n\t\\\\end{equation}\n\twhere $ \\\\mu=\\\\frac{1}{N_x N_Y N_z}\\\\sum\\\\limits_{i=1}^{N_x}\\\\sum\\\\limits_{j=1}^{N_y}\\\\sum\\\\limits_{k=1}^{N_z} G_{ijk} $\n\n\t\\\\item Finally the matrices $\\\\mathbf{A_x}, \\\\mathbf{A_y}, \\\\mathbf{A_z}$ are normalized to obtain the templates $\\\\mathbf T_x, \\\\mathbf T_y, \\\\mathbf T_z$:\n\t\t\\\\begin{equation}\n\t\t\t\\\\mathbf{T}:=\\\\frac{1}{\\\\left\\\\|\\\\mathbf{A}\\\\right\\\\|} \\\\, \\\\mathbf{A}  = \\\\frac{1} {\\\\sqrt{ \\\\sum\\\\limits_i \\\\sum\\\\limits_j a_{ij}^{2}}} \\\\, \\\\mathbf{A}\n\t\t\\\\end{equation}\n\n\\\\end{enumerate}\n\n\n\\\\paragraph{Fiber Detection}\n\nAs previously mentioned fiber detecting process in gray scale input data set $\\\\mathbf G$ is performed subsequently for all three directions x, y and z. During these three cycles three temporary binary data sets $\\\\mathbf B^x, \\\\mathbf B^y, \\\\mathbf B^z$ are obtained, having each voxel labeled with one of two possible values 0 (fluid phase) or 1 (collagen phase).\n\n\\\\begin{enumerate}\n\n\t\\\\item Initially all voxels of first x-slice (yz-plane) with brightnesses larger than the mean gray scale $\\\\mu$ are investigated. This restriction is also only due to decrease computation time. Without this restriction the fraction of additionally detected fiber voxels is less than $10^{-5}$. This small fraction is negligible since it does not significantly affect the resulting poresize distributions on the one hand. And, on the other hand, would increase performance time drastically by a factor of 5, because 80\\\\% of all voxels are darker than the mean brightness. Consequently all voxels with gray scales smaller than $\\\\mu$ are set to 0 in the binarized data set $\\\\mathbf B^x$.   \n\t\n\t\\\\item The voxels to be investigated are taken as centers of small 2D-images located in the yz-plane. These images are represented as matrices with same size as the corresponding templates. These matrices are the unknown patterns to be compared with the template. We call them the search patterns $\\\\mathbf S_n$. \n\t\n\t\\\\item From each entry of $\\\\mathbf S_n$ the local mean value $\\\\mu_n$ is subtracted:\n\t\\\\begin{equation}\n\t  (s_{ij})_{H \\\\times W}:=(s_{ij})_{H \\\\times W}-\\\\mu_n\n\t\\\\end{equation}\n\t\t\\\\begin{equation}\n\t\t\t\\\\mathbf{S_n}:=\\\\mathbf{S_n}-\\\\mu_n=\n\t\t\t\\\\begin{pmatrix}\n\t\t\t\ts_{1,1}^n-\\\\mu_n & s_{1,2}^n-\\\\mu_n & \\\\cdots &  s_{1,W}^n-\\\\mu_n \\\\\\\\\n\t\t\t\ts_{2,1}^n-\\\\mu_n & s_{2,2}^n-\\\\mu_n & \\\\cdots & s_{2,W}^n-\\\\mu_n \\\\\\\\\n\t\t\t\t\\\\vdots & \\\\vdots & \\\\ddots & \\\\vdots \\\\\\\\\n\t\t\t\ts_{H,1}^n-\\\\mu_n & s_{H,2}^n-\\\\mu_n & \\\\cdots & s_{H,W}^n-\\\\mu_n\n\t\t\t\\\\end{pmatrix} \n\t\t\\\\end{equation}\n\t\twhere $\\\\mu_n=\\\\frac{1}{H\\\\cdot W}\\\\sum\\\\limits_{i=1}^{H}\\\\sum\\\\limits_{j=1}^{W}s_{ij}^n$\n\t\n\t\\\\item The search patterns are normalized:\n\t\t\\\\begin{equation}\n\t\t\t\\\\mathbf{S_n}:=\\\\frac{1}{\\\\left\\\\|\\\\mathbf{S_n}\\\\right\\\\|} \\\\, \\\\mathbf{S_n}  = \\\\frac{1} {\\\\sqrt{ \\\\sum\\\\limits_i \\\\sum\\\\limits_j (s^n_{ij})^{2}}} \\\\, \\\\mathbf{S_n}\n\t\t\\\\end{equation}\n\t\n\t\\\\item Now the mismatch $d_n$ between search patterns $\\\\mathbf{S_{n}}$ and template pattern for detection in x-direction $\\\\mathbf{T_{x}}$ is computed. The smaller $d_n$ is, the more possible the central voxel of the search pattern belongs to collagen phase. As mismatch measuring metric we chose the Euclidean distance in feature space. Hence we call $d_n$ the matching distance.\n\t\\\\begin{equation}\n\t\td_{n}=\\\\left\\\\|\\\\mathbf{S_{n}}-\\\\mathbf{T_x}\\\\right\\\\|=\\\\sqrt{\\\\sum\\\\limits_{i}\\\\sum\\\\limits_{j}\\\\left(s_{ij}^{n}-t_{ij}^{x}\\\\right)^{2}}\n\t\\\\end{equation}\n\tSince all matrices are normalized, the range of $d_n$ is $\\\\left[0,2\\\\right]$ where $d_n=0$ means perfect matching.\n\n\t\\\\item The calculated matching distances $d_n$ are compared with the threshold for x-directional detection $\\\\theta_d^x$. This threshold defines whether the search pattern is sufficiently similar to the template, so the pattern\\'s central voxel may be a fiber voxel. For $d_{n}>\\\\theta_d^x$ the corresponding voxels in $\\\\mathbf B^x$ are set to 0. Note that all thresholds $\\\\theta_d^x, \\\\theta_d^y, \\\\theta_d^z$ are not chosen arbitrarily, but derived adaptively from the input data. The detailed method of defining these thhresholds will be described in later section.\n\t  \t\n\t\\\\item To all voxels being considered ($d_{n}<\\\\theta_d^x$) a local minimum filter is applied, labeling only local best matching voxels as belonging to collagen phase by assigning the value 1, while all others are set to 0. After having finished this step the first x-slice of input data set is completely binarized and stored in the temporary binary data set $\\\\mathbf{B^x}$.\n\t\n\t\\\\item All previous steps are repeated for all other x-slices resulting the first binarized data set $\\\\mathbf{B^x}$. \n\t\t\n\t\\\\item Some fibers oriented nearly parallel to any x-slice and hence being not sliced orthogonally may be not well detected since their surrounding area shows a different appearence and is not sufficiently similar to the corresponding template. Therefore the complete detection process is repeated in y- and z-direction. Having all y- and z-slices binarized two more binary data sets $\\\\mathbf{B^y}$ and $\\\\mathbf{B^z}$ are obtained. \n\t\n\t\\\\item Finally the three temporary reconstruction results are combined to one binary data set using logical OR:\n\t\\\\begin{equation}\n\t  B_{ijk} := B_{ijk}^x \\\\vee B_{ijk}^y \\\\vee B_{ijk}^z \\\\ \\\\ \\\\ \\\\ \\\\forall \\\\ i,j,k \n\t\\\\end{equation}\n\\\\end{enumerate}\n\n\n\n\\\\paragraph{Post-Processing}\n\nAs a post-processing step all false positive voxels resulting from noise in the image stack are removed (i.e. set to 0). These voxels can be identified as isolated voxels labeld as collagen phase while all of their 26 neighbor voxels in a $3\\\\times3\\\\times3$ kernel are labeled as fluid phase.\n\n\n\n\\\\paragraph{Define optimal Template Sizes}\n\nThe right template size $\\\\mathbf{T} \\\\in \\\\mathds R^{H\\\\times W}$ is crucial for reliably detecting fibers in adequate time. On the one hand the template must not be too small, because otherwise the pattern is not completely covered. On the other hand templates should not be too large to limit computation time. So how to find ideal values for $H$ and $W$ automatically without any user interaction? A good indication is given by the algebraic sign of template\\'s matrix entries. Since all entries are reduced by subtracting the mean gray scale $\\\\mu$, positive entries correspond to gray scales brighter than and vice versa negative entries to gray scales darker than the average. Taking into account that the patterns to be detected are resulting from convolution of bright fibers with the point spread function it is reasonable to consider positive matrix entries as belonging to pattern\\'s foreground, while negative entries represent the surrounding background.\nHence, if the template is sized in a kind that all outer entries are negative and at the same time all inner entries are positive it is warranted that the pattern is completely covered by the template. Furthermore using both, positive and negative matrix entries, implies better use of complete domain of definition and contrast enhancement since matching distances $d_n$ only will be minimal if the template is perfectly centered at the patterns being investigated.\n\t\nInitially height $H$ and width $W$ are set to arbitrary small values, for example $H=15$ and $W=9$. Then the templates are iteratively resized and recalculated until the optimal size is found. Since computating the template takes only a few seconds the complete runtime is not affected significanly by these iterations.\n\n\n\n\\\\paragraph{Define optimal Matching Thresholds}\n\nThe optimal thresholds $\\\\theta_d^x$, $\\\\theta_d^y$ and $\\\\theta_d^z$ are also defined iteratively. It is clear that it depends on the thresholds how many voxels are labeled as fiber voxels. Because both templates and search matrices are normalized the maximum range of matching distances $d_n$ is $\\\\left[0,2 \\\\right]$ and consequently the optimal thresholds are in the same range as well.\n\\\\newline\nIf matrices are treated as vectors in high-dimensional feature space, three special cases can be distinguished:\n\\\\begin{description}\n\t\\\\item[Identity] \n\t\t\\\\noindent\\\\hspace*{20mm} $d_n=0$ \\\\noindent\\\\hspace*{10mm} $\\\\Rightarrow$ \\\\noindent\\\\hspace*{10mm} $\\\\mathbf{S}_n \\\\ \\\\equiv \\\\ \\\\ \\\\mathbf{T}$\n\t\n\t\\\\item[Orthogonality] \n\t\t\\\\noindent\\\\hspace*{10.5mm} $d_n=\\\\sqrt{2}$ \\\\noindent\\\\hspace*{7mm} $\\\\Rightarrow$ \\\\noindent\\\\hspace*{10mm} $\\\\mathbf{S}_n\\\\ \\\\ \\\\bot \\\\  \\\\ \\\\ \\\\mathbf{T}$\n\t\n\t\\\\item[Inversion] \n\t\t\\\\noindent\\\\hspace*{20mm} $d_n=2$ \\\\noindent\\\\hspace*{10mm} $\\\\Rightarrow$ \\\\noindent\\\\hspace*{10mm} $\\\\mathbf{S}_n \\\\ =-\\\\mathbf{T}$\n\\\\end{description}\nWhere orthogonality means a miximum dissimilarity between template and search matrix. Inversion implies identical absolute values of corresponding matrix entries with inverted algebraic signs.\nHence $\\\\left[\\\\sqrt{2},2 \\\\right]$ is no expedient range for the thresholds which rather must be within $\\\\left[0,\\\\sqrt{2} \\\\right]$. \n\nSince reconstructed fibers should be skeletonized, the most probably number of direct fiber voxel neighbors $E_{mode}$ in a $3^3$-neighborhood of a central fiber voxel turns out to be a good criterion. Extensive evaluations of simulated line networks showed $E_{mode}=3$ in case of perfect skeletonization. \n\nObviously there is not only a single value for thresholds that achieves $E_{mode}=3$, but rather a range, where the optimal thresholds would be the top of this range, because this causes a maximum number of detected fibers while simultaniously the constraint $E_{mode}=3$ is fulfilled.\n\\\\newline\nThe threshold for each reconstruction direction x, y and z is defined in two subsequent steps. Firstly a threshold that fulfills $E_{mode}=4$ is searched using a binary search algorithm. And secondly the found threshold is reduced step by step until it fulfills $E_{mode}=3$. \n\n\\\\emph{Binary Search}\nBinary search is an efficient standard algorithm for searching a specified value by halfing the number of items to check with each iteration \\\\cite{cor09}\\\\cite{aro09}.\nInitially the threshold is set to the middle of the range to be searched $\\\\left[0,\\\\sqrt{2} \\\\right]$\n\\\\begin{equation}\n\t\\\\theta_d^{(0)}:=\\\\frac{0+\\\\sqrt{2}}{2}=\\\\frac{1}{\\\\sqrt{2}}\n\\\\end{equation}\nand the bounds are defined\n\\\\begin{align}\n\t\\\\theta_d^{max(0)} & := \\\\sqrt{2} \\\\\\\\\n\t\\\\theta_d^{min(0)} & := 0\n\\\\end{align}\n\\\\newline\nThen the following steps are repeated until the stop criterion is fulfilled:\n\\\\begin{enumerate}\n\t\\\\item The fiber detection algorithm is performed with recent threshold $\\\\theta_d^{(n)}$. To limit computation time not the complete data set (containing $512 \\\\times 512 \\\\times 597$ voxels) is used but only a smaller sub set containing $150 \\\\times 150 \\\\times 150$ voxels.\n\t\t\n\t\\\\item The most probably number of fiber voxel neighbors $E_{mode}$ is evaluated.\n\t\n\t\\\\item The threshold and the bounds of searching range are updated: \\\\\\\\\n\t\tIf $E_{mode}<4$ then: \n\t\t\\\\begin{align}\n\t\t\t\\\\theta_d^{max(n+1)} & := \\\\theta_d^{max(n)} \\\\\\\\\n\t\t\t\\\\theta_d^{min(n+1)} & := \\\\theta_d^{(n)}\t\t\\\\\\\\\n\t\t\t\\\\theta_d^{(n+1)} & := (\\\\theta_d^{max(n+1)}+\\\\theta_d^{min(n+1)})\/2\n\t\t\\\\end{align}\n\t\tIf $E_{mode}>4$ then: \n\t\t\\\\begin{align}\n\t\t\t\\\\theta_d^{max(n+1)} & := \\\\theta_d^{(n)}\t \\\\\\\\\n\t\t\t\\\\theta_d^{min(n+1)} & := \\\\theta_d^{min(n)}\t\\\\\\\\\n\t\t\t\\\\theta_d^{(n+1)} & := (\\\\theta_d^{max(n+1)}+\\\\theta_d^{min(n+1)})\/2\n\t\t\\\\end{align}\n\t\tIf $E_{mode}=4$ then binary search is stopped.\n\\\\end{enumerate}\n\n\\\\emph{Reduction of threshold}\nThe threshold is now iteratively reduced until $E_{mode}=3$:\n\\\\begin{enumerate}\n\t\\\\item The fiber detection algorithm is performed with recent threshold $\\\\theta_d^{(n)}$. Again due to limit computation time not the complete data set is used but a sub set. However containing now more voxels (i.e. $250 \\\\times 250 \\\\times 250$) than previously used for binary search to increase accuracy.\n\t\n\t\\\\item The most probably number of fiber voxel neighbors $E_{mode}$ is evaluated.\n\t\n\t\\\\item If $E_{mode}=4$ then the recent threshold is reduced by subtracting a small $\\\\varepsilon$. \\\\\\\\\n\tIf $E_{mode}=3$ then the optimal threshold is found and the iteration loop is stopped. \\\\\\\\\n\tNote that the smaller $\\\\varepsilon$ is chosen the more exact the best threshold is found on the one hand but on the other hand the more iteration steps are required. As a good compromise to achieve both high accuracy and runtime limitation we found $\\\\varepsilon=0.01$. \n\\\\end{enumerate}\n\n\n\n\\\\paragraph{Quality Measures}\n\nTo evaluate the validity of our algorithm we defined two quality measures based on the surrogate data sets. The \\\\emph{tolerant correlation of data sets} and the \\\\emph{correlation of distributions of nearest obstacle distances}. \n\nThe reconstructed fibers, derived from grayscale surrogate data sets, are not exactly straight but rather do smoothly fluctuate. That means that for a given solid phase voxel in binary surrogate data set the position of the corresponding solid phase voxel in the reconstructed data set may differ. However the range of difference does not exceed one voxel size in each direction.     \n\nTaking into account that such small fluctuations do not affect the network\\'s global properties, we do not compare the binary data sets (i.e. binary surrogate and binary reconstruction), but local averaged data sets. Therefore both binary arrays to be compared are converted to grayscale arrays by setting each voxel to the average of itself and its 26 direct neighbors. This method provides two significant advantages. On the one hand the information of local solid voxel density is preserved since larger average values are corresponding to a larger number of solid phase voxels within a $3^3$-neighborhood. On the other hand independency against small differences from exact positions is achieved. After having converted the data sets to be compared the correlation coefficient of voxel values in both arrays is calculated.\n\nFORMEL?????\n\nTo compare the distributions of nearest obstacle distances $p(r_{nod})$ and $q(r_{nod})$ in binary surrogate and reconstruction result, firstly both distributions are evaluated and secondly the empirical correlation coefficient is calculated.\n\n\nFORMEL?????\n\n","title":"Methods","dateCreated":"2011-08-15 10:12:31","dateContentTouched":"2011-08-30 14:04:15","dateImagesTouched":"2011-08-15 10:12:31","dateFilesTouched":"2011-08-15 10:12:31","dateCommentsTouched":"2011-08-29 10:04:49","files":[],"images":[],"comments":[{"id":1,"user":"claus.metzner@gmx.net","content":"Hey, das wird !","dateCreated":"2011-08-19 14:05:59"},{"id":2,"user":"claus.metzner@gmx.net","content":"Ich glaube, wir k\u00f6nnen das Kapitel doch einfach \\\"Methods\\\" nennen.","dateCreated":"2011-08-19 14:08:11"},{"id":4,"user":"Patrick.Krauss@web.de","content":"Evtl muss die Reihenfolge der paragraphs noch ge\u00e4ndert werden.","dateCreated":"2011-08-24 06:14:11"},{"id":5,"user":"Patrick.Krauss@web.de","content":"Claus, ich bin mit einigen \u00dcberschriften noch nicht zufrieden. Hast du Vorschl\u00e4ge?","dateCreated":"2011-08-24 06:14:37"},{"id":6,"user":"janina.lange@web.de","content":"Template generation?\nThreshold definition?","dateCreated":"2011-08-24 07:59:13"},{"id":7,"user":"janina.lange@web.de","content":"typo:\ncollagene fiber. ---> collagen","dateCreated":"2011-08-24 08:00:30"}],"users":{"claus.metzner@gmx.net":{"mayEdit":1,"dateRead":"2011-09-02 11:46:54","dateTouched":"2011-08-29 14:50:15"},"janina.lange@web.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-30 07:47:55"},"Patrick.Krauss@web.de":{"mayEdit":1,"dateTouched":"2011-08-30 14:04:15","dateRead":"2011-08-30 14:32:22"},"nadine.r.lang@gmx.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-28 09:52:17"}},"dateUsersTouched":"2011-08-24 07:07:32","maxCommentId":9},{"id":9,"content":"Many biological materials self-organize by the polymerization of protein molecules into fibrils, which eventually cross-link among each other and thus form a complex network, or gel. If the thickness of the fibrils is negligible compared to the pore size, the resulting structure can be mathematically described as a disordered line network. In general, the functional properties of these biomaterials, such as their mechanical stiffness on the macro scale, or their permeability for diffusing particles and for actively migrating cells, depend on the geometrical details of the microscopic network structure. In order to study the relation between geometry and function, it is therefore desirable to extract, or reconstruct, the network structure from a given sample of the material. Ideally, such a reconstruction is based on a purely optical, three-dimensional (3D) scan of the sample. In this paper, we will focus on the particular problem of reconstructing the line network structure of collagen gels from confocal image stacks, but the described methods will be useful in other contexts as well.\n\nThe protein fibrils in collagen gels are surrounded by a liquid medium. In order to observe the fibrils against this background with fluorescence microscopy, a lengthy staining procedure is required. Unfortunately, the staining also leaves the gels in a toxic state for cells, thus being disadvantageous for cell migration experiments. A much more convenient way is therefore the use of reflection microscopy, which does not require such staining. With a confocal microscope in the reflection mode, the 3D volume of the collagen gel can be recorded as a series of 2D images, each representing a cross-section of the gel volume at a given focal depth $z$. Individual fibers can be resolved in that way, although they are broadened in the images by the point-spread-function of the optical system. A disadvantage of reflection mode microscopy is the \\\"blind spot\\\" problem, i.e. the fact that the apparent brightness of fibers decreases quickly with their angle relative to the image plane, leaving all fibers beyond a critical cut-off angle invisible. Nevertheless, the resulting image stack, a 3D array of voxels with gray levels, forms the raw data from which the original line network (except the entirely invisible lines) is to be reconstructed.\n\nOne aspect of the reconstruction is the binarization of the gray level image stack, so that each voxel is assigned one of two possible values, corresponding either to the solid phase (1, collagen fibers) or the liquid phase (0, surrounding medium). Roughly speaking, this decision is made on the basis of the voxel gray levels, since the solid phase voxels tend to be brighter than those of the liquid. Another aspect of the reconstruction is the skeletonization of the solid phase, so that the optically broadened fibers are reduced to their central (medial) axis, with a width of only one voxel. Most of the standard reconstruction methods realize these two aspects subsequently in a two-step process, i.e. first the image stack is binarized and then the such-defined solid phase is skeletonized by some kind of thinning operation. In this paper, we shall present a method based on pattern matching, which achieves both aspects in a single step.\n\n\n\\\\paragraph{Criteria for reconstruction methods}\n\nBefore constructing a new reconstruction method, it is essential to first define as clearly as possible the criteria which the method should eventually meet. Our first criterion was (1) {\\\\em The absence of user-adjustable parameters}. This requirement was born out of the observation that in many standard reconstruction methods with adjustable parameters, the results can depend strongly on the setting of these parameters, yet often no objective rules are provided for the correct choice of the settings. Since a reconstruction method resembles a measurement instrument, its results should be sufficiently independent from any such subjective factors. Therefore, even if a reconstruction algorithm internally contains parameters, those have to be automatically adapted to the current raw data, according to predefined optimization rules. A related criterion is (2) {\\\\em The insensitivity to variations in the input data quality}: If, for example, the average brightness level in the image stack or the signal-to-noise ratio have a drastic effect on the reconstruction, these results cannot be trusted. Other criteria are connected to the validation of the reconstructions. In cases when only measured image stacks are available and no independent physical methods can be used to verify the results, the only way of validation is by human, subjective inspection. On top of this subjective condition, however, we regard objective tests as essential. For this purpose, artificial image stacks can be computed from virtual line networks of a known structure. The test criterion is then (3) {\\\\em The correct reconstruction of known networks}. The final two points are design criteria: Just as a human specialist, the reconstruction method should make use of a-priori knowledge about the network structure. For example, the decision whether a given voxel belongs to the solid or liquid phase should not only be based on the gray level of the single voxel under question. Rather, the algorithm should (4){\\\\em take into account the whole brightness distribution} (i.e. the pattern) surrounding each investigated voxel. Finally, the algorithm should (5) {\\\\em recognize fibers by their line-like property}.\n\n\\\\paragraph{Existing reconstruction methods}\n\nThere already exists a huge variety of methods that can be used for the reconstruction problem. As already mentioned above, a large class of these methods works with two separate steps of binarization and skeletonization. The simplest way to binarize a gray-level-stack is by comparing each individual voxel grayscale with a global, \\\"suitably chosen\\\" threshold value $\\\\theta$ and to assign all voxels that are brighter than $\\\\theta$ to the solid phase. As we shall demonstrate below, this method naturally leads to binarized arrays with many artifacts, i.e. false positive and false negative voxels, and all these problems have to be fixed in the subsequent skeletonization step \\\\cite{pud98}\\\\cite{ma96}\\\\cite{lee94}\\\\cite{pro07}\\\\cite{ren09}\\\\cite{wan07}. This includes the simple removal of isolated solid-phase voxels, which can result from noise or dirt particles in the medium. More demanding, it includes the thinning of the broadened binarized fibers to their medial axis of one voxel diameter. Binarization can also lead to the disintegration of fibers, so that closing methods, consisting of dilatation with subsequent erosion steps \\\\cite{soi99}\\\\cite{sze10}, have to be applied as well.\n\nAnother class of methods is based on edge detection with convolution kernels \\\\cite{soi99}\\\\cite{sze10}, using, for example, Laplace filters \\\\cite{soi99}\\\\cite{sze10} oder Sobel operators \\\\cite{soi99}\\\\cite{sze10}. This class of methods is also plagued with the production of artifacts that have to be removed afterwards.\n\nFinally, we would like to mention the class of learning algorithms, such as vector clustering methods \\\\cite{gan07} and neural networks \\\\cite{bis96}, for example the K-Means algorithm \\\\cite{bra00} or RBF networks \\\\cite{how07}. A significant advantage of such methods is their ability to automatically adapt to the specific properties of the data at hand. We note that our proposed pattern matching algorithm generates its template patterns automatically from the data and can therefore be considered as a learning algorithm as well.\n\n\\\\paragraph{Problems with existing methods}\n\nA detailed summary and comparison of all the available reconstruction methods is beyond the scope of this paper. Instead, we shall briefly consider the simple example of global threshold binarization and discuss some of its fundamental shortcomings. This will be useful to highlight the advantages of the pattern matching method proposed later.\n\nWe start with an image stack recorded by reflection microscopy. Let us assume that the grayscales of the image stack are coded with 8 bit, i.e. all brightness values $B$ are in the range $B \\\\in [0,255]$, with $B=0$ corresponding to completely dark and $B=255$ to maximum bright voxels. In our setup (Leica...), a typical distribution $p(B)$ of brightness values has a sharp peak around $B=15$ and a very flat, tail towards large values (compare, for example, Fig.X). The reasonable range of binarization thresholds $\\\\theta$ is located somewhere within this tail. However, the distribution $p(B)$ itself offers no hint as to where the optimum threshold point should be set.\n\nIn order to gain more insight we turn to artificially generated image stacks. This requires realistic models of, both, the line network itself and its transformation into cross-sectional images by the microscope. As described in more detail in the Methods section, we use a \\\"Mikado\\\" model for the line network, where straight lines of fixed lengths and isotropic orientations are distributed throughout the volume with a homogeneous density. The model of the imaging process takes into account the broadening (simulated by a convolution with a point spread function), the blind spot effect (i.e. a gradual darkening of steep fibers) \\\\cite{jaw09} and the addition of random noise. Using these models, the resulting image stacks have statistical properties almost indistinguishable from measured image stacks (compare Sec...), but with the advantage that the original mathematical line network is known precisely.\n\nIs is possible to perfectly reconstruct the original line network using global threshold binarization ? This would require the existence of a threshold $\\\\theta$, such that all liquid-phase voxels have brightnesses below and and all solid-phase-voxels brightnesses above this threshold. However, when we use our synthetic stack and plot the brightness distributions $p_S(B)$ and $p_L(B)$ of the two phases separately, we find in general two peaks with a significant overlap (compare Fig. X). This means that no global threshold can be found, even in in principle, for separating the two phases, without also producing some false positive and false negative voxels.\n\nThe voxels with brightnesses in the overlap interval include, for example, isolated bright points due to noise. It would be relatively easy to remove such cases in a subsequent post-processing step. The overlap interval also includes liquid phase voxels from the narrow gaps between two fibers, which have been raised in brightness beyond the threshold by the superposition of the fibers\\' point spread functions. This effect would lead to a merging of the two close-by fibers in the binarized image and would require a much more sophisticated procedure to be repaired. Finally, the overlap region includes the voxels of fiber segments that are simply too steep, and therefore too dark, to exceed the threshold. We note that a human observer (or a recognition method using the a-priori knowledge about the line-like nature of the objects to be found) could still recognize such dark fiber segments quite easily.\n\nWe thus see that the threshold binarization has some fundamental limitations. To a certain extent, the method can be improved by using variable thresholds, which take into account the local brightness conditions in the environment of each voxel to be binarized. This, however, can already be viewed as a first step towards our pattern matching method that will be discussed in the following.\n\n\\\\paragraph{Pattern matching in line networks}\n\nPattern matching methods recognize features in the image stacks by comparing the brightness patterns of small sub volumes of the stack with pre-defined templates. It is possible to define a \\\"matching quality\\\" that is independent from the absolute pattern brightness, but incorporates the a-priori-knowledge about the features to be found (see Methods section). In the case of line networks, the features to be found are short line segments, which can be oriented in arbitrary directions.\n\nThe number of required templates turns out to be impractically large in 3D. However, the situation becomes much more convenient when only 2D cross-sections are used for the pattern matching: The vertical cross-section of a broadened line segment with a plane is a roundish spot of finite size that can be easily recognized by 2D pattern matching. The shape of the spot will be varying slightly as the angle of intersection becomes less than 90 degrees. For angles less than 45 degrees, the distortion of the spot becomes too large to match the template, but in this case the same line segment can be easily recognized by its intersection with a perpendicular plane. Therefore, all line segments (solid voxels) can be recognized by sequentially scanning through the x-, y- and z-planes of the sample volume. This binarization method turns out to be much more reliable and robust than the simple threshold method.\n\nThe similarity between the cross-sectional brightness pattern and the template will be largest if the template is located exactly at the center of the finite spot. Therefore, the medial axes of the broadened line segments can be identified as local minima of the mismatching measure. In this way, the 2D pattern-matching simultaneously achieves a skeletonization of the broadened fibers.\n\nWe note that this method meets the design criteria (4) and (5) imposed before. In order to eliminate all internal parameters (1), we have implemented an automatic template generator, which is entirely based on the input image stack and requires no user intervention. We will demonstrate in the Results section that our method is also extremely robust with respect to changing quality of the input data (2) and yields reconstructions that reproduce simulated line networks almost perfectly (3).","title":"Introduction","dateCreated":"2011-08-15 10:13:38","dateContentTouched":"2011-08-30 13:05:04","dateImagesTouched":"2011-08-15 10:13:38","dateFilesTouched":"2011-08-15 10:13:38","dateCommentsTouched":"2011-08-30 13:57:51","files":[],"images":[],"comments":[{"id":12,"user":"janina.lange@web.de","content":"fibrils (ich kenne die hier verwendete Schreibweise nur aus dem Franz\u00f6sischen?)\ncut-off (viel h\u00e4ufiger mit Bindestrich?)\ntypo: Absatz \u00fcber Criteria for reconstruction methods:\ndecision\n\nFrage:\nIst das wirklich ein Kriterium, auf das wir uns verlassen k\u00f6nnen? -->\n(3) THE AGREEMENT OF THE ALGORITHMIC RECONSTRUCTION WITH THAT OF A HUMAN SPECIALIST\n\n\n\u00fcber Existing reconstruction methods:\nshould not only be based only --> Wiederholung!\n\nwas die Punkte 1-6 betrifft: eventuell 5+6 zusammenfassen? bessere Gruppierung m\u00f6glich? Liest sich leicht zusammengew\u00fcrfelt?\n\n\ntypo: 3. Absatz in Problems with existing methods:\nprecisely\n","dateCreated":"2011-08-21 09:05:51"},{"id":13,"user":"janina.lange@web.de","content":"Vorletzter Absatz in Problems with existing methods:\nfiber\\'s point spread functions. --> sollten es nicht die Point spread functions beider Fasern sein, die \u00fcberlappen? also fibers\\' ???\n\n\ntypo: zweiter Absatz in Pattern matching in line networks:\nits intersection","dateCreated":"2011-08-21 09:15:14"},{"id":14,"user":"Patrick.Krauss@web.de","content":"Den ersten Satz im Absatz \u00fcber die lernenden Algorithmen m\u00fcsste man etwas anders formulieren, da k-Means und RBF-Netze Beispiele f\u00fcr Vektor-Clustering-Methoden bzw. Neuronale Netze sind, wobei die Grenzen zwischen VC und NN flie\u00dfend sind.\nMein Vorschl\u00e4g w\u00e4re:\nFinally, we would like to mention the class of learning algortihms, such as vector clustering methods (Refs) and neural networks (Refs), for example the K-Means algorithm (Refs) or RBF networks (Refs).","dateCreated":"2011-08-21 11:28:55"},{"id":15,"user":"Patrick.Krauss@web.de","content":"Generell w\u00fcrde ich vorschlagen dass wir uns auf die Verwendung folgender Begriffe einigen, da sie so auch in der entsprechenden Literatur verwendet werden:\n\n\\\"pattern detection\\\":\nganz allgemein\nfinden eines prototypischen Musters, z.B. ein Gesicht oder ein Auto\n\n\\\"pattern recognition\\\":\netwas spezieller\nerkennen und unterscheiden verschiedener Auspr\u00e4gungen eines Prototyps,\nz.B. Gesicht von Herrn Maier \/ Gesicht von Frau M\u00fcller\noder BMW \/ Audi\n\n\\\"template\/pattern matching\\\":\nmusterbasierte Suche\nVergleich von unbekannten Mustern mit einer Schablone (template) unter Verwendung einer \u00c4hnlichkeits-Metrik","dateCreated":"2011-08-21 11:29:14"},{"id":16,"user":"claus.metzner@gmx.net","content":"Ich habe die meisten Vorschl\u00e4ge von Janina ber\u00fccksichtigt, insbesondere habe ich die HUMAN INSPECTION jetzt nicht mehr als besonders wichtiges Kriterium erw\u00e4hnt. Den Fehler mir \\\"decisions\\\" kann ich nicht finden. Das Wort \\\"fibril\\\" schein nach Leo kein Problem zu sein ?","dateCreated":"2011-08-22 07:03:07"},{"id":17,"user":"claus.metzner@gmx.net","content":"Patrick\\'s ge\u00e4nderter Satz \u00fcber lernende Algo\\'s ist eingef\u00fcgt.","dateCreated":"2011-08-22 07:05:10"},{"id":18,"user":"janina.lange@web.de","content":"Tut mir leid, das hab ich falsch formuliert. Du hast einmal \\\"The protein fibrilles in collagen gels are surrounded by a liquid medium.\\\" fibrilles mit doppeltem ll geschrieben und einmal fibrils. Ich kenn pers\u00f6nlich nur fibrils und wollte eher drauf hinweisen, dass man eine einheitliche Schreibweise verwenden sollte.....\n\\\"Roughly speaking, this decission is made on the basis of the voxel gray levels, since the solid phase voxels tend to be brighter than those of the liquid. \\\" ist im Absatz oberhalb von Criteria for....\n\n\n","dateCreated":"2011-08-22 07:10:30"},{"id":19,"user":"claus.metzner@gmx.net","content":"Mit Patrick\\'s genaueren Definitionen \u00fcber Pattern-Detection\/Recognition\/Matching bin ich einverstanden. Habe den Intro-Text an 3 Stellen entprechend modifiziert.","dateCreated":"2011-08-22 07:14:40"},{"id":20,"user":"claus.metzner@gmx.net","content":"Danke, Janina, jetzt konnte ich die Fehler verbessern.","dateCreated":"2011-08-22 07:18:37"},{"id":21,"user":"Patrick.Krauss@web.de","content":"Citations hinzugef\u00fcgt. Und entsprechende Refernces ins bib-File integriert.","dateCreated":"2011-08-24 05:55:10"}],"maxCommentId":22,"users":{"claus.metzner@gmx.net":{"mayEdit":1,"dateRead":"2011-08-31 08:13:37","dateTouched":"2011-08-22 07:52:32"},"nadine.r.lang@gmx.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-28 09:52:32"},"janina.lange@web.de":{"mayEdit":1,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-30 12:51:42"},"Patrick.Krauss@web.de":{"mayEdit":1,"dateTouched":"2011-08-30 13:05:04","dateRead":"2011-08-30 13:57:35"}},"dateUsersTouched":"2011-08-19 14:17:43"},{"id":10,"content":"We present a fast and robust method to reconstruct a disordered network of thin biopolymers, such as in a collagen gel, from a blurred and noisy graylevel image stack recorded with a confocal microscope in the reflection mode. Our pattern matching algorithm simultaneously performs a binarization and skeletonization of the line network and is free of user-adjustable parameters, in contrast to the many of the alternative methods in use. The quality of the method is objectively evaluated by reconstructing artificial image stacks generated from line networks with a known structure. In addition, we use measured stacks to investigate the dependence of the results on the microscope settings during image recording. ","title":"Abstract","dateCreated":"2011-08-15 10:14:14","dateContentTouched":"2011-08-18 12:00:53","dateImagesTouched":"2011-08-15 10:14:14","dateFilesTouched":"2011-08-15 10:14:14","dateCommentsTouched":"2011-08-15 10:14:14","files":[],"images":[],"comments":[],"users":{"claus.metzner@gmx.net":{"mayEdit":1,"dateRead":"2011-08-25 14:02:38","dateTouched":"2011-08-18 12:00:53"},"janina.lange@web.de":{"mayEdit":0,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-30 12:53:04"},"Patrick.Krauss@web.de":{"mayEdit":0,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-29 13:02:57"},"nadine.r.lang@gmx.de":{"mayEdit":0,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-28 09:53:04"}},"dateUsersTouched":"2011-08-17 15:47:24"},{"id":11,"content":"P. Krauss, C. Metzner, J. Lange, N. Lang and B. Fabry","title":"Authors and Affiliations","dateCreated":"2011-08-15 10:14:25","dateContentTouched":"2011-08-15 10:18:39","dateImagesTouched":"2011-08-15 10:14:25","dateFilesTouched":"2011-08-15 10:14:25","dateCommentsTouched":"2011-08-15 10:14:25","files":[],"images":[],"comments":[],"users":{"claus.metzner@gmx.net":{"mayEdit":1,"dateRead":"2011-08-19 16:19:41","dateTouched":"2011-08-17 15:47:24"},"janina.lange@web.de":{"mayEdit":0,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-21 08:46:52"},"Patrick.Krauss@web.de":{"mayEdit":0,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-21 11:28:07"},"nadine.r.lang@gmx.de":{"mayEdit":0,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-28 09:53:12"}},"dateUsersTouched":"2011-08-17 15:47:24"},{"id":12,"content":"Reconstructing fiber networks from confocal image stacks","title":"Title","dateCreated":"2011-08-15 10:14:38","dateContentTouched":"2011-08-15 16:31:13","dateImagesTouched":"2011-08-15 10:14:38","dateFilesTouched":"2011-08-15 10:14:38","dateCommentsTouched":"2011-08-15 10:14:38","files":[],"images":[],"comments":[],"users":{"claus.metzner@gmx.net":{"mayEdit":1,"dateRead":"2011-08-24 05:21:08","dateTouched":"2011-08-17 15:47:24"},"janina.lange@web.de":{"mayEdit":0,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-21 08:47:00"},"Patrick.Krauss@web.de":{"mayEdit":0,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-21 11:28:05"},"nadine.r.lang@gmx.de":{"mayEdit":0,"dateTouched":"1985-09-02 14:00:00","dateRead":"2011-08-28 09:53:14"}},"dateUsersTouched":"2011-08-17 15:47:24"}],"users":{"K4EsV4xvQr":{"email":"claus.metzner@gmx.net","type":"editor","notificationCooldown":"3600","dateJoined":"2011-08-15 10:01:42","lastNotification":"2011-08-29 10:04:16"},"FK9s9IECNV":{"email":"nadine.r.lang@gmx.de","type":"editor","notificationCooldown":"3600","dateJoined":"2011-08-16 10:08:25","lastNotification":"2011-08-29 10:04:17"},"XO3zmMn0GX":{"email":"janina.lange@web.de","type":"editor","notificationCooldown":"3600","dateJoined":"2011-08-16 10:08:35","lastNotification":"2011-08-29 10:04:17"},"384QhLcIUm":{"email":"Patrick.Krauss@web.de","type":"subscriber","notificationCooldown":"3600","dateJoined":"2011-08-16 10:08:43","lastNotification":"2011-08-29 10:04:18"},"mrZv4n10DE":{"email":"Patrick.Krauss@web.de","type":"editor","notificationCooldown":"3600","dateJoined":"2011-08-16 10:08:52","lastNotification":"2011-08-29 10:04:18"},"UFJTBUd1sn":{"email":"Patrick.Krauss@web.de","type":"editor","notificationCooldown":"3600","dateJoined":"2011-08-21 11:22:18","lastNotification":"2011-08-29 10:17:03"}},"drafts":{"K4EsV4xvQr":{"title":"","content":"","files":[],"images":[],"dateContentTouched":"2011-08-15 13:31:24","dateImagesTouched":"2011-08-15 13:31:24","dateFilesTouched":"2011-08-15 13:31:24"},"FK9s9IECNV":{"title":"","content":"","files":[],"images":[],"dateContentTouched":"2011-08-16 10:08:25","dateImagesTouched":"2011-08-16 10:08:25","dateFilesTouched":"2011-08-16 10:08:25"},"XO3zmMn0GX":{"title":"","content":"","files":[],"images":[],"dateContentTouched":"2011-08-16 10:08:35","dateImagesTouched":"2011-08-16 10:08:35","dateFilesTouched":"2011-08-16 10:08:35"},"384QhLcIUm":{"title":"","content":"","files":[],"images":[],"dateContentTouched":"2011-08-16 10:08:43","dateImagesTouched":"2011-08-16 10:08:43","dateFilesTouched":"2011-08-16 10:08:43"},"mrZv4n10DE":{"title":"","content":"","files":[],"images":[],"dateContentTouched":"2011-08-16 10:08:52","dateImagesTouched":"2011-08-16 10:08:52","dateFilesTouched":"2011-08-16 10:08:52"},"UFJTBUd1sn":{"title":"","content":"","files":[],"images":[],"dateContentTouched":"2011-08-21 11:22:18","dateImagesTouched":"2011-08-21 11:22:18","dateFilesTouched":"2011-08-21 11:22:18"}},"version":4}